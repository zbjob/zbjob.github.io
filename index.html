
<!DOCTYPE html>

<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-129714236-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

        gtag('config', 'UA-129714236-1');
        </script>
<script type="application/ld+json">
            {
                "@context": "http://schema.org",
                "@type": "Person",
                "name": "Bo Zhao",
                "url": "https://zbjob.github.io",
                "jobTitle": "Assistant Professor",
                "alumniOf": "Aalto University ",
                "gender": "male",
                "image": "https://zbjob.github.io/images/zhao_2.jpg",
                "sameAs": [
                    "https://amor.cms.hu-berlin.de/~zhaobo/",
                    "https://www.linkedin.com/in/bo-zhao-054b7aa8/",
                    "https://twitter.com/bo_zhao_",
                    "https://scholar.google.de/citations?user=R6igYYYAAAAJ&hl=en",
                    "https://www.facebook.com/bo.zhao.779205",
                    "https://github.com/zbjob",
                    "https://www.instagram.com/bo.zhao_real/",
                    "https://zbjob.github.io/"
                    ]
            }
        </script>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<title>Bo Zhao</title>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="Bo Zhao" name="description">
<meta content="Bo Zhao, Aalto University" name="keywords">
<meta content="Bo Zhao" name="author">
<!-- Facebook and Twitter integration -->
<meta content="" property="og:title"/>
<meta content="" property="og:image"/>
<meta content="" property="og:url"/>
<meta content="" property="og:site_name"/>
<meta content="" property="og:description"/>
<meta content="" name="twitter:title"/>
<meta content="" name="twitter:image"/>
<meta content="" name="twitter:url"/>
<meta content="" name="twitter:card"/>
<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
<link href="favicon.ico" rel="shortcut icon"/>
<!-- <link href='https://fonts.googleapis.com/css?family=Work+Sans:400,300,600,400italic,700' rel='stylesheet' type='text/css'> -->
<!-- Animate.css -->
<link href="css/animate.css" rel="stylesheet"/>
<!-- Icomoon Icon Fonts-->
<link href="css/icomoon.css" rel="stylesheet"/>
<!-- Bootstrap  -->
<link href="css/bootstrap.css" rel="stylesheet"/>
<!-- Theme style  -->
<link href="css/style.css" rel="stylesheet"/>
<!-- Modernizr JS -->
<script src="js/modernizr-2.6.2.min.js"></script>
<!-- FOR IE9 below -->
<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->
</meta></meta></meta></head>
<body style="background-image: url(images/bg_img.jpg);">
<div id="fh5co-main">
<div class="fh5co-tab-wrap">
<ul class="fh5co-tab-menu">
<li class="active"><a data-tab="1" href="#"><span class="icon icon-user"></span><span class="menu-text">Profile</span></a></li>
<li><a data-tab="2" href="#"><span class="icon icon-graduation-cap"></span><span class="menu-text">Education</span></a></li>
<li><a data-tab="3" href="#"><span class="icon icon-book"></span><span class="menu-text">Publications</span></a></li>
<li><a data-pie="yes" data-tab="4" href="#"><span class="icon icon-dollar"></span><span class="menu-text">Grants/Awards</span></a></li>
<li><a data-pie="yes" data-tab="5" href="#"><span class="icon icon-group"></span><span class="menu-text">Group</span></a></li>
<li><a data-pie="yes" data-tab="6" href="Bo_Zhao_CV.pdf"><span class="icon icon-paperclip"></span><span class="menu-text">CV</span></a></li>
<li><a data-pie="yes" data-tab="7" href="#"><span class="icon icon-globe"></span><span class="menu-text">Services</span></a></li>
<li><a data-pie="yes" data-tab="8" href="#"><span class="icon icon-compass"></span><span class="menu-text">Vacancies</span></a></li>
<li><a data-pie="yes" data-tab="9" href="#"><span class="icon icon-presentation"></span><span class="menu-text">Seminars</span></a></li>
<li><a data-pie="yes" data-tab="10" href="#"><span class="icon icon-phone"></span><span class="menu-text">Contact</span></a></li>
</ul>
<div class="fh5co-tab-content active" data-content="1">
<div class="fh5co-content-inner text-center">
<div class="row row-bottom-padded-sm">
<div class="col-md-12">
<figure>
<img alt="Free HTML5 Wesbite Template by FreeHTML5.co" height="256" src="images/zhao_2.jpg" width="424"/>
<figcaption> <h6> Shot by Matti Ahlgren, Aalto University </h6></figcaption>
</figure>
<h1>Bo Zhao</h1>
<p align="justify"><strong><mark>Openings:</mark> I am recruiting PhD students and postdoctoral researchers in data management systems, ML systems, and hybrid classical–quantum systems. 
Please see the <a href="https://zbjob.github.io/vacancies">Vacancies</a> tab for current positions and application instructions.</strong></p>
<p align="justify">
I am a tenure-track Assistant Professor in the <a href="https://www.aalto.fi/en/department-of-computer-science">Department of Computer Science</a> at <a href="https://www.aalto.fi/en">Aalto University</a>, where I lead the <b>Aalto Data-Intensive Systems Group (ADIS)</b>. 
At Aalto CS, I serve as the responsible professor for the <a href="https://www.aalto.fi/en/programmes/masters-programme-in-computer-communication-and-information-sciences/curriculum-2024-2026#20-study-track--big-data-and-large-scale-computing/">Big Data and Large-Scale Computing</a> study track in the Master’s programme.
I am also affiliated with the <a href="https://fcai.fi/">Finnish Center for Artificial Intelligence (FCAI)</a>, the <a href="https://www.hiit.fi/">Helsinki Institute for Information Technology (HIIT)</a>, and the <a href="https://instituteq.fi/qdoc/">Quantum Doctoral Pilot Programme (QDOC)</a>. 
I serve as the spokesperson for the Aalto Hub in the <a href="https://www.europarl.europa.eu/RegData/etudes/BRIE/2025/769492/EPRS_BRI(2025)769492_EN.pdf">LUMI AI Factory</a> project.
</p>
<p align="justify">
My research develops <b>efficient, scalable data-intensive systems</b> that turn data into reliable decisions. 
I work across the software stack—spanning distributed ML systems, data management systems, and emerging quantum computing systems—with a focus on <b>performance, scalability, and energy efficiency</b>.
Representative themes include:
</p>
<ul align="justify">
<li>Distributed training and serving systems for large models (including RL post-training)</li>
<li>Data and state management for ML pipelines (e.g., data loading, scheduling, RAG/GraphRAG under tight latency budgets)</li>
<li>Hybrid classical–quantum workflows (e.g., real-time QEC decoding, scheduling across HPC + QPU, and end-to-end toolchains)</li>
</ul>
<p align="justify">
My long-term goal is to uncover the fundamental connections between data management and modern machine learning, and to build systems that are more <b>transparent, robust, and efficient</b>.
More details are available in my <a href="RS_Zhao_pub.pdf">research statement</a> and related <a href="https://www.aalto.fi/en/news/bo-zhao-believes-machine-learning-systems-will-become-like-dictionaries-everyday-tools-we-all-use-to">press coverage</a>.
</p>
<p align="justify">
Before joining Aalto, I was an Assistant Professor at <a href="https://www.qmul.ac.uk">Queen Mary University of London</a>. 
I previously worked as a postdoctoral researcher at <a href="http://www.imperial.ac.uk/">Imperial College London</a> in the <a href="http://lsds.doc.ic.ac.uk/">Large-Scale Data &amp; Systems (LSDS)</a> group with <a href="https://www.imperial.ac.uk/people/prp">Prof. Peter Pietzuch</a>. 
I received my PhD from the <a href="https://www.informatik.hu-berlin.de/en/forschung-en/gebiete/dbis">Databases and Information Systems Group</a> at <a href="https://www.hu-berlin.de/en">Humboldt-Universität zu Berlin</a>, advised by <a href="https://www.informatik.hu-berlin.de/en/forschung-en/gebiete/dbis/people/matthiasweidlich">Prof. Matthias Weidlich</a>. 
Earlier, I worked with the <a href="https://www.parallel.informatik.tu-darmstadt.de/home.html">Parallel Programming</a> group with <a href="https://www.parallel.informatik.tu-darmstadt.de/laboratory/team/wolf/wolf.html">Prof. Felix Wolf</a> at <a href="http://www.rwth-aachen.de/">RWTH Aachen University</a> and <a href="https://www.tu-darmstadt.de/index.en.jsp">TU Darmstadt</a>.
</p>
</div>
</div>
<!--
					<div class="row">
						<div class="col-md-12 fh5co-counter">
							<div class="fh5co-number fh5co-left">10</div>
							<div class="fh5co-text">
								<h3 class="border-bottom">Years of experience in Web Design</h3>
								<p>Far far away, behind the word mountains, far from the countries.</p>
							</div>
						</div>
					</div>
                    -->
<ul class="fh5co-social">
<li><a href="https://twitter.com/bo_zhao_"><i class="icon-twitter"></i></a></li>
<li><a href="https://scholar.google.de/citations?user=R6igYYYAAAAJ&amp;hl=en"><i class="icon-google"></i></a></li>
<li><a href="http://www.linkedin.com/in/bo-zhao-054b7aa8/"><i class="icon-linkedin"></i></a></li>
<li><a href="https://www.facebook.com/bo.zhao.779205"><i class="icon-facebook"></i></a></li>
<li><a href="https://github.com/zbjob"><i class="icon-github"></i></a></li>
<li><a href="http://gitlab.informatik.hu-berlin.de/zhaobo"><i class="icon-gitlab"></i></a></li>
<li><a href="https://www.instagram.com/bo.zhao_real/"><i class="icon-instagram"></i></a></li>
</ul>
</div>
</div>
<div class="fh5co-tab-content" data-content="2">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<div class="fh5co-text">
<h2>Experience</h2>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-graduation-cap"></i>
</div>
<div class="fh5co-text">
<h2>SEP.2023-Present</h2>
<p> Assistant Professor
                                    <br/> Aalto University, Finland</p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-graduation-cap"></i>
</div>
<div class="fh5co-text">
<h2>JAN.2023-AUG.2023</h2>
<p> Assistant Professor
                                    <br/> Queen Mary University of London, UK</p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-graduation-cap"></i>
</div>
<div class="fh5co-text">
<h2>2021-2022</h2>
<p>Post-doctoral researcher
                                    <br/> Imperial College London, UK</p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-briefcase"></i>
</div>
<div class="fh5co-text">
<h2>2019-2019</h2>
<p>Software Development Engineer 
                                    <br/> Amazon Web Services, Redshift Team</p>
</div>
</div>
<div class="fh5co-text">
<h2>Education</h2>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-graduation-cap"></i>
</div>
<div class="fh5co-text">
<h2>2016-2022</h2>
<p>PhD in Computer Science
                                    <br/> Humboldt-Universität zu Berlin, Germany</p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-graduation-cap"></i>
</div>
<div class="fh5co-text">
<h2>May.2017-Jun.2017</h2>
<p>Visiting PhD student in Computer Science
                                    <br/>University of Queensland, Australia</p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-graduation-cap"></i>
</div>
<div class="fh5co-text">
<h2>2013-2015</h2>
<p>Visiting master student in Computer Science
                                    <br/>RWTH-Aachen University, Germany</p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-graduation-cap"></i>
</div>
<div class="fh5co-text">
<h2>2012-2015</h2>
<p>Master of Science in Computer Science
                                    <br/>Xi'an Jiaotong University, China</p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-graduation-cap"></i>
</div>
<div class="fh5co-text">
<h2>2008-2012</h2>
<p>Bachelor of Science in Computer Science
                                    <br/>Wuhan Institute of Technology, China</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="fh5co-tab-content" data-content="4">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-dollar"></i>
</div>
<div class="fh5co-text">
<h2>AthenaRL: Scalable and Flexible Distributed Reinforcement Learning Systems</h2>
<p> Funding agency: Research Council of Finland — Academy Project Funding 
                                    <br/>Duration: 2024-2028
                                    <br/>Role: Principal investigator (PI) 
                                    <br/>Amount: 780,114 EUR
                                    </p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-dollar"></i>
</div>
<div class="fh5co-text">
<h2>AthenaQEC: Real-Time Decoding of over 1,000 Logical Qubits</h2>
<p> Funding agency: Finnish Quantum Flagship Exploratory Projects: Quantum Future (P4) 
                                    <br/>Duration: 2025-2027
                                    <br/>Role: Principal investigator (PI) 
                                    <br/>Amount: 75,000 EUR
                                    </p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-dollar"></i>
</div>
<div class="fh5co-text">
<h2>LARA: Large Language Models for Quantum Machine Learning Algorithms</h2>
<p>Funding agency: Business Finland — Quantum Computing Research Call 
                                    <br/>Duration: 2024-2026 
                                    <br/>Role: Principal investigator (PI)
                                    <br/>Amount: 349,915 EUR (out of 700,000 EUR)
                                    </p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-dollar"></i>
</div>
<div class="fh5co-text">
<h2>FlexMoE: Flexible Efficient Mixture-of-Experts Systems</h2>
<p>Funding agency: The Finnish Doctoral Program Network in Artificial Intelligence 
                                    <br/>Duration: 2024-2027 
                                    <br/>Role: Principal investigator (PI)
                                    <br/>Amount: 112,011 EUR
                                    </p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-dollar"></i>
</div>
<div class="fh5co-text">
<h2>LashQ: Large Language Model Augmented Scalable Hybrid Quantum-Classical Computing Framework</h2>
<p>Funding agency: Research Council of Finland–the Finnish Quantum Flagship’s Quantum Doctoral Pilot Programme
                                    <br/>Duration: 2024-2027
                                    <br/>Role: Principal investigator (PI)
                                    <br/>Amount: 112,011 EUR
                                    </p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-trophy"></i>
</div>
<div class="fh5co-text">
<h2>Distinguished Reviewer Award for VLDB 2025</h2>
<p><a href="VLDB_DRAward.pdf">Certificate</a>
<br/>Granting Organizations: VLDB Endowment Inc.
                                    <br/>International Conference on Very Large Databases, 31.Aug.2025-5.Sept.2025
                                    <br/>The Queen Elizabeth II Centre, London, United Kingdom
                                    </p>
</div>
</div>
<div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-trophy"></i>
</div>
<div class="fh5co-text">
<h2>The 4th Best Course for the Academic Year 2023-2024</h2>
<p><a href="Best-course-CS-E4190.pdf">Certificate</a>
<br/>Granting Organizations: Department of Computer Science, Aalto University 
                                    <br/>December.2024
                                    </p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="fh5co-tab-content" data-content="3" id="Publications">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<h2>Publications <a href="https://dblp.uni-trier.de/pid/94/4810-19.html"><font size="4px"><u>DBLP</u></font></a> <a href="https://scholar.google.de/citations?user=R6igYYYAAAAJ&amp;hl=en"><font size="4px"><u>Google Scholar</u></font></a></h2>





























<!--
							<div class="fh5co-feature">
								<div class="fh5co-icon">
									<i class="icon-black-tie"></i>
									<i class="icon-book"></i>
									<i class="icon-phone"></i>
									<i class="icon-user"></i>
								</div>
								<div class="fh5co-text">
									<h2>1999-2004</h2>
									<h3>Previous Ltd Co.</h3>
									<p>Far far away, behind the word mountains, far from the countries.</p>
								</div>
							</div>
                            -->
<h3>Distributed training, serving, and hardware-aware AI systems</h3><p style="margin-top:-8px; margin-bottom:18px;">Systems for scalable training/serving of large models and performance-aware runtimes on modern hardware.</p><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
Jie Sun, Shaohang Wang, Zimo Zhang, Zhengyu Liu, Yunlong Xu, Peng Sun, Bo Zhao, Bingsheng He, Fei Wu, Zeke Wang
                                        <br/> <a href=""><font size="3px">BiAttention: Efficient Generative Recommender Serving with Bipartite Attention</font></a>
<br/>ACM International Conference on Architectural Support for Programming Languages and Operating Systems (<b>ASPLOS</b>), Pittsburgh, USA, 2026</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Zheyue Tan, Mustapha Abdullahi, Tuo Shi, Huining Yuan, Zelai Xu, Chao Yu, Boxun Li, Bo Zhao
                                        <br/> <a href="https://arxiv.org/pdf/2510.05943"><font size="3px">EARL: Efficient Agentic Reinforcement Learning Systems for Large Language Models</font></a>
<br/>Workshop on Systems for Agentic AI (<b>SAA</b>), in conjunction with the ACM Symposium on Operating Systems Principles (<b>SOSP</b>), Seoul, Korea, 2025</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
Zheyue Tan, Zhiyuan Li, Tao Yuan, Dong Zhou, Weilin Liu, Yueqing Zhuang, Yadong Li, Guowei Niu, Cheng Qin, Zhuyu Yao, Congyi Liu, Haiyang Xu, Boxun Li, Guohao Dai, Bo Zhao, Yu Wang
                                        <br/> <a href="https://arxiv.org/pdf/2510.17483"><font size="3px">ReXMoE: Reusing Experts with Minimal Overhead in Mixture-of-Experts
</font></a>
<br/>Pre-print in arXiv, 2025</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Marcel Wagenländer, Guo Li, Bo Zhao, Luo Mai, Peter Pietzuch
                                        <br/> <a href="SOSP24.pdf"><font size="3px">TENPLEX: Changing Resources of Deep Learning Jobs using Parallelizable Tensor Collections</font></a>
<br/>In the Proc. of Symposium on Operating Systems Principles (<b>SOSP</b>), Austin, TX, USA, 2024</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Huanzhou Zhu*, Bo Zhao*, Gang Chen, Weifeng Chen, Yijie Chen, Liang Shi, Yaodong Yang, Peter Pietzuch, Lei Chen (*equal contribution)
                                        <br/> <a href="ATC23.pdf"><font size="3px">MSRL: Distributed Reinforcement Learning with Dataflow Fragments</font></a>
<br/>In the USENIX Annual Technical Conference (<b>USENIX ATC</b>), Boston, MA, USA, 2023.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
Huining Yuan, Zelai Xu, Zheyue Tan, Xiangmin Yi, Mo Guang, Kaiwen Long, Haojia Hui, Boxun Li, Xinlei Chen, Bo Zhao, Xiao-Ping Zhang, Chao Yu, Yu Wang
                                        <br/> <a href="https://arxiv.org/pdf/2510.15414"><font size="3px">MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games
</font></a>
<br/>Pre-print in arXiv, 2025</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
				Boxun Li, Yadong Li, Zhiyuan Li, Congyi Liu, Weilin Liu, Guowei Niu, Zheyue Tan, Haiyang Xu, Zhuyu Yao, Tao Yuan, Dong Zhou, Yueqing Zhuang, Bo Zhao, Guohao Dai, Yu Wang
                                        <br/> <a href="https://arxiv.org/pdf/2507.17728"><font size="3px">Megrez2 Technical Report</font></a>
<br/>Pre-print in arXiv, 2025</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
Song Liu, Jie Ma, Zhenyuan Zhang, Xinhe Wan, Bo Zhao, Weiguo Wu
                                        <br/> <a href="TC25-Scalpel.pdf"><font size="3px">Scalpel: High Performance Contention-Aware Task Co-Scheduling for Shared Cache Hierarchy</font></a>
<br/>In IEEE Transactions on Computers, 2025</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>

<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Alessandro Fogli, Bo Zhao, Peter Pietzuch, Jana Giceva
                                        <br/> <a href="EuroSys26.pdf"><font size="3px">CHARM: Chiplet Heterogeneity-Aware Runtime Mapping System</font></a>
<br/>European Conference on Computer Systems (<b>EuroSys</b>), Edinburgh, UK, 2026</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>

<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Alessandro Fogli, Bo Zhao, Peter Pietzuch, Maximilian Bandle, Jana Giceva
                                        <br/> <a href="VLDB24.pdf"><font size="3px">OLAP on Modern Chiplet-Based Processors</font></a>
<br/>In the Proc. of International Conference on Very Large Data Bases (<b>VLDB</b>), Guangzhou, China, 2024</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Song Liu, Xinhe Wan, Zengyuan Zhang, Bo Zhao, Weiguo Wu

                                        <br/> <a href="TurboStencil.pdf"><font size="3px">TurboStencil: You Only Compute Once for Stencil Computation</font></a>
<br/>In <b>Future Generation Computer Systems</b>, Volume 146, 2023.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Song Liu, Bo Zhao, Qing Jiang, Weiguo Wu
                                        <br/> <a href="CJC-17.pdf"><font size="3px">A Semi-Automatic Coarse-Grained Parallelization Approach for Loop Optimization And Irregular Code Sections</font></a>
<br/>In Chinese Journal of Computers, 2017, 40(9): 2127-2147.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Bo Zhao, Zhen Li, Ali Jannesari, Felix Wolf, Weiguo Wu
                                        <br/> <a href="CGO-W-Zhao.pdf"><font size="3px">Dependence-Based Code Transformation for Coarse-Grained Parallelism</font></a>
<br/>In Proc. of the International Workshop on Code Optimisation for Multi and Many Cores (<b>COSMIC</b>) held in conjunction with <b>CGO</b>, San Francisco, CA, USA, ACM, February 2015.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Zhen Li, Bo Zhao, Ali Jannesari, Felix Wolf
                                        <br/> <a href="ICA3PP.pdf"><font size="3px">Beyond Data Parallelism: Identifying Parallel Tasks in Sequential Programs</font></a>
<br/>In Proc. of 15th International Conference on Algorithms and Architectures for Parallel Processing (<b>ICA3PP</b>), Zhangjiajie, China, Lecture Notes in Computer Science, Springer, November 2015.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Song Liu, Weiguo Wu, Bo Zhao, Qing Jiang
                                        <br/> <a href="JCRD-15.pdf"><font size="3px">Loop Tiling for Optimization of Locality and Parallelism</font></a>
<br/>In Journal of Computer Research and Development, 2015, 52(5): 1160-1176.</font></p>
</div>
</div><h3>Data and state management for ML pipelines</h3><p style="margin-top:-8px; margin-bottom:18px;">State-efficient processing, shared execution, and data-centric foundations for ML and streaming workloads.</p><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
					Cong Yu, Tuo Shi, Matthias Weidlich, Bo Zhao
                                        <br/> <a href="https://arxiv.org/pdf/2507.04872"><font size="3px">SHARP: Shared State Reduction for Efficient Matching of Sequential Patterns</font></a>
<br/>In the Proc. of International Conference on Very Large Data Bases (<b>VLDB</b>), Boston, MA, USA, 2026</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Bo Zhao
                                        <br/> <a href="https://edoc.hu-berlin.de/bitstream/handle/18452/25352/dissertation_zhao_bo.pdf?sequence=5&amp;isAllowed=y"><font size="3px">State Management for Efficient Event Pattern Detection</font></a>
<br/><b>Dissertation</b>, Humboldt-Universität zu Berlin, 2022.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Bo Zhao, Han van der Aa, Nguyen Thanh Tam, Nguyen Quoc Viet Hung, Matthias Weidlich
                                        <br/> <a href="SIGMOD21.pdf"><font size="3px">EIRES: Efficient Integration of Remote Data in Event Stream Processing</font></a>
<br/>In Proc. of the 47th ACM SIGMOD International Conference on Management of Data (<b>SIGMOD</b>), Xi'an, China, ACM, June 2021.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Bo Zhao, Nguyen Quoc Viet Hung, Matthias Weidlich
                                        <br/> <a href="ICDE20.pdf"><font size="3px">Load Shedding for Complex Event Processing: Input-based and State-based 
                                            Techniques</font></a>
<br/>In Proc. of the 36th IEEE International Conference on Data Engineering (<b>ICDE</b>), Dallas, TX, USA, IEEE, April 2020.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Bo Zhao
                                        <br/> <a href="ICDE-PHD.pdf"><font size="3px">Complex Event Processing under Constrained Resources by State-based Load Shedding</font></a>
<br/>In Proc. of the 34th IEEE International Conference on Data Engineering (<b>ICDE</b>), Paris, France, IEEE, April 2018.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">Gururaghav Raman, Jimmy Chih-Hsien Peng, Bo Zhao, Matthias Weidlich
                                        <br/> <a href="PES-GM19.pdf"><font size="3px">Dynamic Decision Making for Demand Response through Adaptive Event Stream Monitoring</font></a>
<br/>In Proc. of 2019 IEEE Power &amp; Energy Society General Meeting (<b>PESGM</b>), Atlanta, GA, USA. IEEE, August 2019.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Gururaghav Raman, Bo Zhao, Jimmy Chih-Hsien Peng, Matthias Weidlich
                                        <br/> <a href="AppliedEnergy.pdf"><font size="3px">Adaptive incentive-based demand response with distributed non-compliance assessment</font></a>
<br/>In <b>Applied Energy</b>, Volume 326, 2022.</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Lei You, Lele Cao, Mattias Nilsson, Bo Zhao, Lei Lei
                                        <br/> <a href="https://arxiv.org/pdf/2401.13112"><font size="3px">Distributional Counterfactual Explanation With Optimal Transport</font></a>
<br/>In the Proc. of International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>) (Oral, top 2%), Thailand, 2025</font></p>
</div>
</div><h3>Hybrid classical–quantum workflows</h3><p style="margin-top:-8px; margin-bottom:18px;">Software systems and learning-driven pipelines that connect quantum programs with classical infrastructure.</p><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
					Valter Uotila, Väinö Mehtola, Ilmo Salmenperä, Bo Zhao
                    <br/> <a href="https://arxiv.org/pdf/2511.04243"><font size="3px">Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum Machine Learning Ansatzes</font></a>
<br/>IEEE/ACM International Workshop on Quantum Software Engineering (<b>Q-SE</b>), in conjunction with the IEEE/ACM International Conference on Software Engineering (<b>ICSE</b>), Rio de Janeiro, Brazil, 2026</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
					Cong Yu, Valter Uotila, Shilong Deng, Qingyuan Wu, Tuo Shi, Songlin Jiang, Lei You, Bo Zhao
                                        <br/> <a href="https://arxiv.org/pdf/2510.00967"><font size="3px">QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL</font></a>
<br/> Pre-print, 2025 </font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
					Valter Uotila, Cong Yu, Bo Zhao
                                        <br/> <a href="https://www.arxiv.org/pdf/2511.13033"><font size="3px">ZX-DB: A Graph Database for Quantum Circuit Simplification and Rewriting via the ZX-Calculus</font></a>
<br/> Pre-print, 2025 </font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Linus Jern, Valter Uotila, Cong Yu, Bo Zhao
                                        <br/> <a href="QCE25-AgentQ.pdf"><font size="3px">Agent-Q: Fine-Tuning Large Language Models for Quantum Circuit Generation and Optimization</font></a>
<br/>IEEE International Conference on Quantum Computing and Engineering (<b>QCE</b>), Albuquerque, New Mexico, USA, 2025</font></p>
</div>
</div><div class="fh5co-feature">
<div class="fh5co-icon">
<i class="icon-file-text"></i>
</div>
<div class="fh5co-text">
<p align="left"><font size="2.5px">
                                        Valter Uotila, Julia Ripatti, Bo Zhao
                                        <br/> <a href="QCE25-HUBO-QAOA.pdf"><font size="3px">Higher-Order Portfolio Optimization with Quantum Approximate Optimization Algorithm</font></a>
<br/>IEEE International Conference on Quantum Computing and Engineering (<b>QCE</b>), Albuquerque, New Mexico, USA, 2025</font></p>
</div>
</div><div style="height:10px;"></div></div>
</div>
</div>
</div>
<div class="fh5co-tab-content" data-content="10">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<p>Email: bo.zhao@aalto.fi 
                            <br/>Tel. : +358 503227953 
                            </p>
<p>Mail Address:
                            <br/>Tietotekniikan laitos, P.O.Box 15400, FI-00076 Aalto 

                            <p>Visiting Address:
                            <br/>A108, Department of Computer Science, Aalto University
                            <br/>Konemiehentie 2, 02150 Espoo, Finland 
						</p></p></div>
<!--
						<div class="col-md-4 col-sm-6 col-xs-12 text-center">
							<div class="chart" data-percent="95"><span><strong>HTML5</strong>95%</span></div>
						</div>
						<div class="col-md-4 col-sm-6 col-xs-12 text-center">
							<div class="chart" data-percent="93"><span><strong>CSS3</strong>93%</span></div>
						</div>
						<div class="col-md-4 col-sm-6 col-xs-12 text-center">
							<div class="chart" data-percent="90"><span><strong>jQuery</strong>90%</span></div>
						</div>

						<div class="col-md-4 col-sm-6 col-xs-12 text-center">
							<div class="chart" data-percent="89"><span><strong>PHP</strong>89%</span></div>
						</div>
						<div class="col-md-4 col-sm-6 col-xs-12 text-center">
							<div class="chart" data-percent="85"><span><strong>MySQL</strong>85%</span></div>
						</div>
						<div class="col-md-4 col-sm-6 col-xs-12 text-center">
							<div class="chart" data-percent="90"><span><strong>AngularJS</strong>90%</span></div>
						</div>
                        -->
</div>
</div>
</div>
<div class="fh5co-tab-content" data-content="5">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<p>ADIS is funded by <a href="https://www.aka.fi/en/">Research Council of Finland</a>, <a href="https://www.businessfinland.fi/en/for-finnish-customers/services/funding">Business Finland</a>, the <a href="https://fcai.fi/doctoral-program">Finnish Doctoral Program Network in Artificial Intelligence (AI-DOC)</a>, and the <a href="https://instituteq.fi/qdoc/">Quantum Doctoral Pilot Programme (QDOC)</a>.</p>
<h2>Postdoctoral researchers</h2>
<p> <a href="https://tshi92.github.io/tuoshi/">Dr. Tuo Shi</a> (Sept. 2024-)</p>
<p> <a href="https://realzst.github.io/">Dr. Sitong Zhang</a> (May. 2025-)</p>
<h2>Doctoral researchers</h2>
<p> <a href="https://benyucong.github.io/">Cong Yu</a> (Dec.2023-)  </p>
<p> <a href="https://mustious.github.io/">Mustapha Abdullahi</a> (Apr.2024-) </p>
<p> <a href="https://clementinegjx.github.io/about">Jiaxin Guo</a> (Jun.2024-) </p>
<p> <a href="https://hollowman6.github.io/">Songlin Jiang</a> (Sept.2024-) </p>
<p> <a href="https://alirezasamar.com/">Alireza Samar</a> (Oct.2024) </p>
<p> <a href="https://valteruo.github.io/">Valter Uotila</a> (Dec.2024-) </p>
<p> <a href="https://github.com/tanzeyy">Zheyue Tan</a> (Jan.2025-) </p>
<h2>MSc student researchers</h2>
<p> <a href="https://www.linkedin.com/in/baiyan-che-61b54a380/">Baiyan Che</a> (Nov.2025-) </p>
<p> <a href="https://www.linkedin.com/in/zhongxuan-xie/">Zhongxuan Xie</a> (2024-2025, now at ABB Group) </p>
<p> <a href="https://www.linusjern.com/">Linus Jern</a> ( Fall 2024-Summer 2025, now at Boston Consulting Group -&gt; Palantir Technologies) </p>
<h2>Summer intern researchers</h2>
<p> <a href="https://github.com/HalberdOfPineapple">Wenxuan Li</a> (Summer 2024. Home university: University of Cambridge, now at Microsoft Research Asia) </p>
<h2>Visiting PhD students</h2>
<p> <a href="https://zczlsde.github.io/zczlsde_shilong/">Shilong Deng</a> (Spring 2024. Home university: University of Liverpool)</p>
</div>
</div>
</div>
</div>
<div class="fh5co-tab-content" data-content="6">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<p> <a href="Bo_Zhao_CV.pdf">CV Download</a> (updated in August 2025) </p>
</div>
</div>
</div>
</div>
<div class="fh5co-tab-content" data-content="7">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<p> Organizing Committee: UbiComp'25 Local Arrangement Chair</p>
<p> Program Committee: EuroSys'26,27    SIGMOD'26     VLDB'25,26,27     EuroMLSys'26    ICDE'25     CoNEXT'24,25    CIKM'21,22,23</p>
<p> Availability Committee: SIGMOD'22,23</p>
<p> Demonstration Track Committee: ICDE'23,24,25</p>
<p> Student Research Competition Committee: SOSP'25</p>
<p> Journal Reviewer: VLDBJ'25    JMLR'24    TPDS'23</p>
<p> Journal Editor: Proceedings of the ACM on Networking (PACMNET)</p>
<p> Co-Chair: The great talk series, CS Department, Aalto University</p>
</div>
</div>
</div>
</div>
<div class="fh5co-tab-content" data-content="8" id="Vacancies">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<p align="left"><a href="index.html">Aalto Data-Intensive Systems Group (ADIS)</a> is seeking full-time doctoral and postdoctoral researchers in scalable machine learning systems and distributed data-intensive systems. Due to the large volume of applications, I may not be able to reply to all candidates, but I promise to carefully go over each application. Thanks!</p>
<ul compact="">
<li><b>We have several current openings:</b></li>
<li>(1) Postdoc positions (2 openings) in scalable ML systems and/or quantum computing systems</li>
<li>(2) PhD positions (2 openings) in scalable ML systems</li>
<li>(3) HIIT research fellowship in data-intensive systems and ML systems</li>
<li>(4) TA/RA positions at Aalto CS</li>
</ul>

<p> <a>[About the group]</a> We conduct research on efficient data-intensive systems that translate data into value for decision making. The scope of our research spans across multiple subfields, from scalable data-centric machine learning systems to distributed data     stream management systems, as well as code optimization techniques. That is to answer the question “how to co-design multiple layers of the software stack to improve scalability, performance, and energy efficiency of ML systems”. Our long-term goal is to explore and understand the fundamental       connections between data management and modern ML systems to make decision-making more transparent, robust and efficient. Please find more details in our <a href="RS_Zhao_pub.pdf">research statement</a>.
                             </p>
<h3>(1) Postdoc positions (2 openings) in scalable ML systems and/or quantum computing systems</h3>
<p><b>Contract:</b> 12–24 months (depending on funding; extension possible). <b>Start date:</b> flexible (as soon as possible preferred).</p>
                             Requirements
                              <ul compact="">
<li>An excellent PhD degree in Computer Science or a closely related field</li>
<li><b>Track A (Scalable ML / Data Systems):</b> experience in distributed ML training/inference, distributed/networked systems, distributed databases, and/or code optimization</li>
<li><b>Track B (Hybrid Classical–Quantum Systems):</b> experience in hybrid classical–quantum computing systems, in particular quantum error correction, quantum circuit generation, and/or quantum compilation/optimization</li>
<li>Strong publication record in top ML or systems venues (e.g., SIGMOD/VLDB/SOSP/OSDI/EuroSys/SIGCOMM/NSDI/ICML/NeurIPS/ICLR/QEC/QIP), or equivalent evidence of research excellence (e.g., impactful open-source artifact + strong evaluation)</li>
<li>Very good programming skills (Python + system programming languages e.g., C++/Rust)</li>
<li>Strong analytical thinking skills</li>
<li>The ability to work independently and within a larger team</li>
<li>Excellent scientific communication and writing skills in English</li>
</ul>

                             Current project examples (non-exhaustive)
                             <ul compact="">
<li><b>Track A:</b> LLM training/serving systems; distributed RL post-training; GraphRAG/RAG pipelines under strict latency; data loading &amp; preprocessing at scale; state sharing/caching for multi-tenant workloads</li>
<li><b>Track B:</b> real-time decoding for quantum error correction; scheduling across HPC + QPU; end-to-end hybrid workflows; quantum circuit generation/optimization pipelines</li>
</ul>

                             What we offer
                             <ul compact="">
<li>An outstanding research environment at one of the top computer science universities in Europe</li>
<li>A competitive salary from 4,138.43 EUR to 4,323.57 EUR per month (depending on experience and qualifications)</li>
<li>World-class computing resources including the group-exclusive GPU cluster and access to Europe’s fastest supercomputer, LUMI (11,912 GPUs),, as well as quantum computing resources</li>
<li>Many international collaboration opportunities with both academia and industry, and funded travel to conferences</li>
<li>A wide range of staff benefits, flexible working hours, world-leading health care, family support, and social security</li>
</ul>

                             How to apply (rolling review)
                             <ul compact="">
<li><b>Email subject:</b> [Postdoc Application][Track A/B] Full Name</li>
<li>Send Prof. Bo Zhao a single PDF containing: (i) a cover letter (1 page; please indicate Track A/B and 1 project idea), (ii) an academic CV, (iii) a research statement (2–3 pages), and (iv) contact details of three referees. Transcripts and PhD certificate can be provided upon request.</li>
<li><b>Selection process:</b> shortlisted candidates will be invited for a short interview; references may be contacted at a later stage.</li>
</ul>
<h3>(2) PhD positions (2 openings) in scalable ML systems</h3>
<p><b>Contract:</b> up to 4 years (depending on funding). <b>Start date:</b> flexible (as soon as possible preferred).</p>
                             Requirements
                              <ul compact="">
<li>An excellent MSc degree in Computer Science or a closely related field</li>
<li>Solid background in at least one of: distributed ML training/inference, distributed/networked systems, distributed databases, and/or code optimization</li>
<li>Very good programming skills (Python + system programming languages e.g., C++/Rust)</li>
<li>Strong analytical thinking skills</li>
<li>The ability to work independently and within a larger team</li>
<li>Excellent scientific communication and writing skills in English</li>
<li>Prior research experience is a plus (e.g., publications, open-source artifacts, or an excellent MSc thesis)</li>
</ul>

                             Current project examples (non-exhaustive)
                             <ul compact="">
<li>LLM training/serving systems and performance optimization</li>
<li>Distributed RL post-training / scalable optimization</li>
<li>Data loading, preprocessing, and scheduling for large-scale ML</li>
<li>RAG/GraphRAG pipelines under strict latency and cost constraints</li>
<li>Distributed/streaming data systems for ML workloads</li>
</ul>

                             What we offer
                             <ul compact="">
<li>An outstanding research environment at one of the top computer science universities in Europe</li>
<li>A competitive salary from 3,100 EUR to 3,500 EUR per month</li>
<li>World-class computing resources including the group-exclusive GPU cluster and access to Europe’s fastest supercomputer, LUMI (11,912 GPUs),, as well as quantum computing resources</li>
<li>Many international collaboration opportunities with both academia and industry, and funded travel to conferences</li>
<li>A wide range of staff benefits, flexible working hours, world-leading health care, family support, and social security</li>
</ul>

                             How to apply (rolling review)
                             <ul compact="">
<li><b>Email subject:</b> [PhD Application] Full Name</li>
<li>Send Prof. Bo Zhao a single PDF containing: (i) a cover letter (1 page; please describe your fit + preferred topic), (ii) an academic CV, (iii) a research statement / proposal (1–2 pages), and (iv) contact details of two referees. Transcripts (BSc/MSc) can be provided upon request.</li>
<li><b>Selection process:</b> shortlisted candidates will be invited for a short interview; references may be contacted at a later stage.</li>
</ul>
<h3>(3) HIIT research fellowship</h3>
<p align="left">We have Research Fellow and Postdoctoral Fellow Positions funded by The Helsinki Institute for Information Technology (HIIT). Please find details <a href="https://www.hiit.fi/hiit-postdoctoral-and-research-fellow-positions/">here</a>.</p>
<h3>(4) TA/RA positions at Aalto CS</h3>
                             Current TA/RA positions are for Aalto students. We are looking for MSc students with strong CS background.


                             <!--
                                 <p align="left">We have summer internship positions. Aalto students see <a href="https://www.aalto.fi/en/department-of-computer-science/summer-employee-positions-at-the-department-of-computer-science-2023">here</a>. International students see <a href="https://www.    aalto.fi/en/aalto-science-institute-asci/how-to-apply-to-the-asci-international-summer-research-programme">here.</a></p>
                             -->
<p>Successful applicants will conduct impactful research in the field of data-intensive systems and their applications, publish research results in top-tier conferences, and collaborate with other researchers and visit world-leading research groups and industry labs      within our international network (e.g., Imperial College, TUM, MPI-SWS, HU Berlin, NUS, Uni Edinburgh, AWS, Huawei, etc).Previously, we had the pleasure to work with following students <a href="https://marcelwagenlander.com/">Marcel Wagenländer</a>, <a href="https://www.doc.ic.ac.uk/~af6618/        ">Alessandro Fogli</a>, <a href="https://www.imperial.ac.uk/people/jinnan.guo">Jinnan Guo</a>, and <a href="https://mustious.github.io/">Mustapha Abdullahi</a>.
                             </p>
<h3 align="left">About Aalto University, the CS Department, and Finland</h3>
<p align="left">
<a href="https://www.aalto.fi/en">Aalto University</a> is a community of bold thinkers where science and art meet technology and business. It is the largest technology-oriented university in Finland (<a href="https://www.aalto.fi/en/news/aalto-university-ranks-1-in-finland-in-qs-ranking">1st in Finland according to QS ranking 2024</a>). We are committed to identifying and solving grand societal challenges and building an innovative future. Aalto has six schools with nearly 11,000 students and a staff of more than 4000, of which 400 are professors. Diversity is part of who we are, and we actively work to ensure our community’s diversity and inclusiveness in the future as well. This is why we warmly encourage qualified candidates from all backgrounds to join our community.
                            </p>
<p align="left">
<a href="https://www.aalto.fi/en/department-of-computer-science/about-the-department">The Department of Computer Science</a> is the largest department at Aalto and one of the leading computer science research units in northern Europe. It is routinely ranked among the top 10 in Europe and in the top 100 globally (<a href="https://www.shanghairanking.com/rankings/gras/2022/RS0210">Shanghai ranking 51-75</a>, <a href="https://www.usnews.com/education/best-global-universities/computer-science?name=aalto">USNews 71</a>, <a href="https://www.timeshighereducation.com/world-university-rankings/2023/subject-ranking/computer-science#!/length/25/name/aalto/sort_by/rank/sort_order/asc/cols/stats">Times 73</a>, <a href="https://www.topuniversities.com/university-rankings/university-subject-rankings/2023/computer-science-information-systems?&amp;search=aalto">QS 84</a>).  The CS Department is located at the Otaniemi campus in Espoo – one of the most important Northern European technology hubs, with a high concentration of companies, startups and research institutes from the high-tech sector, and with a thriving culture of entrepreneurship. It is less than a 15 minutes metro ride away from the center of Helsinki, capital of Finland. The campus is designed by the renowned architect and designer, <a href="https://en.wikipedia.org/wiki/Alvar_Aalto">Alvar Aalto</a>. Please check out our <a href="https://virtualtour.aalto.fi/">virtual campus experience</a>.
                            </p>
<p align="left">
                            Aalto University is located in Finland which is among the best countries in the world according to many quality of life indicators. For the sixth year in a row (including 2023), Finland is listed as the world's happiest country, according to the <a href="https://worldhappiness.report/">World Happiness Report</a>. Please find more information about <a href="https://www.aalto.fi/en/careers-at-aalto/living-in-finland">living in Finland</a> and the <a href="https://www.aalto.fi/en/services/welcome-to-aalto-university-and-finland-info-package">Aalto information package</a>.
                            
                            Want to know more about us and your future colleagues? You can watch these videos: <a href="https://www.youtube.com/watch?v=5k_og_6zUJQ">Aalto University – Towards a better world</a>, <a href="https://www.youtube.com/watch?v=dUfEGVM-ZP8&amp;feature=youtu.be">Aalto People</a>, <a href="https://www.youtube.com/watch?v=ZK6pDWm1_CE">Shaping a Sustainable Future</a>. Read more about <a href="https://www.aalto.fi/en/careers-at-aalto">working at Aalto</a>.
                            </p>
</div>
</div>
</div>
</div>
<div class="fh5co-tab-content" data-content="9">
<div class="fh5co-content-inner">
<div class="row">
<div class="col-md-12">
<p>The ADIS Seminars provide a forum to discuss the state of the art in systems research with experts from leading academic institutes and industry labs. All events are free to join, please reach out to our group members for accesses. </p>
<h3>Window-based Learned Index</h3>
<p><a href="https://scholar.google.com/citations?user=97k8aygAAAAJ&amp;hl=en">Liang Liang</a>, Imperial College London, 20.Jun.2024, 14:00 EEST, Online</p>
<p><b>[Abstract]</b>
                             Learned indices have shown substantial improvements in lookup perfor- mance. With the advancement of updatable learned indices, they are partic- ularly effective in dynamic environments like stream processing. Data stream processing systems, which allow querying over sliding windows of data streams, require efficient index structures for operations such as aggregation and joins. We introduce FLIRT, a learned index specifically designed for managing in- coming streams of sequential data, such as time-series data, over a window. FLIRT utilizes a piece-wise linear model to reduce lookup times and employs a queue-assembly structure to efficiently support updates.
While FLIRT is optimized for scenarios where the search keys arrive in a spe- cific order, this requirement can be restrictive in diverse streaming environments. The need for sequential key arrivals limits FLIRT’s applicability, for instance, in settings where the order of data arrival (processing time) does not reflect the inherent order of the data events (event-time). To overcome these limita- tions and broaden the use cases, we developed SWIX, a versatile learned index designed for more generic window processing. Unlike FLIRT, SWIX accommo- dates out-of-order key insertions, thereby enhancing its utility in environments where data arrival order is unpredictable. To support its versatility, SWIX em- ploys sophisticated buffering techniques and lightweight structures that enables efficient query execution at a low cost and makes SWIX memory efficient. Our experiments demonstrate that both FLIRT and SWIX achieve excellent per- formance in their respective applications and pave the way for incorporating streaming learned indices into other operations, such as streaming joins.
                             </p>
<p><b>[About the speaker]</b>
 Liang is currently a PhD student at Imperial College London, where he is supervised by Prof. Thomas Heinis and specializes in database research. Before embarking on his PhD, Liang earned a Master’s degree in High Performance Computing with Data Science from the University of Edinburgh with distinction in 2020 and a Master’s degree in Data Science from Monash University with high distinction in 2019. He completed his undergraduate studies in Law at TianGong University in 2016.
Liang’s research focuses on data-oriented streaming workflow systems and streaming learned indices. He has published in to prestigious journals and conferences venues and continues to explore the integration of learned indices into streaming operations, such as joins and aggregations. Additionally, Liang is very interested in combining machine learning methods to enhance streaming tasks, join cardinality estimation, predictive state representations, and hybrid auto-scaling approaches.
</p>
<hr style="width:100%;text-align:left;margin-left:0"/>
<h3>SQL2Circuits: Estimating Metrics for SQL Queries with A Quantum Natural Language Processing Method</h3>
<p><a href="https://valteruo.github.io/">Valter Uotila</a>, University of Helsinki, 26.Mar.2024, 14:00 EET, CS Building B322</p>
<p><b>[Abstract]</b>
                             Quantum computing has developed significantly in recent years. Developing algorithms to estimate various metrics for SQL queries has been an important research question in database research since the estimations affect query optimization and database performance. This work represents a quantum natural language processing (QNLP) -inspired approach for constructing a quantum machine learning model that can classify SQL queries with respect to their execution times, costs and cardinalities. From the quantum machine learning perspective, we compare our model and results to the previous research in QNLP and conclude that our model reaches similar accuracy as the QNLP model in the classification tasks. This indicates that the QNLP model is a promising method even when applied to problems that are not in QNLP. We study the developed quantum machine learning model by calculating its expressibility and entangling capability histograms. The results show that the model has favorable properties to be expressible but also not too complex to be executed on quantum hardware, for example, on the current 20-qubit quantum computer in Finland.
                             </p>
<p><b>[About the speaker]</b>
 Valter Uotila is a second-year doctoral researcher at the University of Helsinki researching quantum computing applications for databases and data management. His research interests are in the intersection of quantum computing, databases and category theory.
</p>
<hr style="width:100%;text-align:left;margin-left:0"/>
<h3>Advances, challenges, and opportunities in Table Representation Learning</h3>
<p><a href="https://www.madelonhulsebos.com/">Madelon Hulsebos</a>, UC Berkeley, 22.Mar.2024, 17:00 EET, Online </p>
<p><b>[Abstract]</b>
The impressive capabilities of transformers have been explored for applications over language, code, images, but the millions of tables have long been overlooked while tables dominate the organizational data landscape and give rise to peculiar challenges. Unlike natural language, tables come with structure, heterogeneous and messy data, relations across tables, contextual interactions, and metadata. Accurately and robustly embedding tables is, however, key to many real-world applications from data exploration and preparation to question answering and tabular ML. In this talk, I will discuss the general approaches taken towards adapting the transformer architecture towards tables and give an overview of the tasks already explored in this space. I will zoom in on some of the shortcomings of these approaches and close with the open challenges and opportunities, and some ongoing work.
                             </p>
<p><b>[About the speaker]</b>
Madelon Hulsebos is a postdoctoral fellow at UC Berkeley. She obtained her PhD from the Informatics Institute at the University of Amsterdam, for which she did research at the MIT Media Lab and Sigma Computing. She was awarded the BIDS-Accenture fellowship for her postdoctoral research on retrieval systems for structured data. Madelon her general research interest is on the intersection of data management and machine learning, with recent contributions in methods, tools and resources for Table Representation Learning.
</p>
<hr style="width:100%;text-align:left;margin-left:0"/>
<h3>Chameleon: a Heterogeneous and Disaggregated Accelerator System for Retrieval-Augmented Language Models</h3>
<p><a href="https://wenqijiang.github.io/">Wenqi Jiang</a>, ETH Zürich, 7.Mar.2024, 14:00 EET, Online </p>
<p><b>[Abstract]</b> 
The recent advances in generative large language models (LLMs) are attributable to the surging number of model parameters trained on massive datasets. However, improving LLM quality by scaling up models leads to several major problems including high computational costs. Instead of scaling up the models, a promising direction, which OpenAI has recently adopted, is known as Retrieval-Augmented Language Model (RALM), which augments a large language model (LLM) by retrieving context-specific knowledge from an external database via vector search. This strategy facilitates impressive text generation quality even with smaller models, thus reducing computational demands by orders of magnitude.
				</p>
<p>
However, RALMs introduce unique system design challenges due to (a) the diverse workload characteristics between LLM inference and retrieval and (b) the various system requirements and bottlenecks for different RALM configurations including model sizes, database sizes, and retrieval frequencies. In this talk, I will present Chameleon, a heterogeneous accelerator system integrating both LLM and retrieval accelerators in a disaggregated architecture. The heterogeneity ensures efficient serving for both LLM inference and retrieval, while the disaggregation allows independent scaling of LLM and retrieval of accelerators to fulfill diverse RALM requirements. Our Chameleon prototype implements retrieval accelerators on FPGAs and assigns LLM inference to GPUs, with a CPU server orchestrating these accelerators over the network. Evaluated on various RALMs, Chameleon exhibits up to 2.16× reduction in latency and 3.18× speedup in throughput compared to the hybrid CPU-GPU architecture.
</p>
<p><b>[About the speaker]</b> 
Wenqi Jiang is a fourth-year Ph.D. student at ETH Zurich, where he is affiliated with the systems group advised by Gustavo Alonso and Torsten Hoefler. Wenqi's research interests span data management, computer architecture, and computer systems. His work primarily focuses on designing post-Moore data systems, which involve cross-stack solutions including algorithm, system, and architecture innovations. Some examples of his work include large language models, vector search, recommender systems, and spatial data processing.
</p>
<hr style="width:100%;text-align:left;margin-left:0"/>
<h3>DeltaZip: Multi-tenant Language Models Serving via Delta Compression</h3>
<p><a href="https://about.yao.sh/">Xiaozhe Yao</a>, ETH Zürich, 26.Feb.2024, 14:00 EET, Online </p>
<p><b>[Abstract]</b> Fine-tuning large language models (LLMs) for downstream tasks can greatly improve model quality, however serving many different fine-tuned LLMs concurrently for users in multi-tenant environments is challenging. Dedicating GPU memory for each model is prohibitively expensive and naively swapping large model weights in and out of GPU memory is slow. Our key insight is that fine-tuned models can be quickly swapped in and out of GPU memory by extracting and compressing the delta between each model and its pre-trained base model. We propose DeltaZip, an LLM serving system that efficiently serves multiple full-parameter fine-tuned models concurrently by aggressively compressing model deltas by a factor of 6× to 8× while maintaining high model quality. DeltaZip increases serving throughput by 1.5× to 3× and improves SLO attainment compared to a vanilla HuggingFace serving system. 
                            </p>
<p><b>[About the speaker]</b> Xiaozhe Yao is a second-year doctoral student at Systems Group, Department of Computer Science, ETH Zürich advised by Prof. Dr. Ana Klimović. Working on a wide spectrum of machine learning and systems, his research direction is to build systems that support large-scale machine learning and democratize machine learning. Prior to ETH, Xiaozhe Yao gained his Master’s degree at the University of Zurich in Data Science, advised by Prof. Dr. Michael Böhlen and Qing Chen. Before that, he completed his Bachelor’s study at Shenzhen University in Computer Science, advised by Prof. Dr. Shiqi Yu. He interned at Shenzhen Institute of Advanced Technology in 2016 as a data scientist.</p>
<hr style="width:100%;text-align:left;margin-left:0"/>
<h3>TempoRL: Efficient Deep Reinforcement Learning with Recurrent Tensors</h3>
<p><a href="https://www.doc.ic.ac.uk/~pms20/">Pedro Silvestre</a>, Imperial College London, 19.Feb.2024, 13:00 EET, Online </p>
<p><b>[Abstract]</b> Reinforcement Learning (RL) is an increasingly relevant area of algorithmic research. Though RL differs substantially from Supervised Learning (SL), today's RL frameworks are often simple wrappers over SL systems. In this talk, we first analyse the differences between SL and RL from the system designer's point-of-view, then discuss the issues and inefficiencies of RL frameworks arising from those differences. In particular, we discuss how the existence
                            of cyclic and dynamic data dependencies in RL forces the decomposition of algorithms into disjoint dataflow graphs, preventing holistic analysis and optimisation.</p>
<p>We then propose TempoRL, a system designed to efficiently capture these cyclic and dynamic data dependencies in a single graph by instead viewing RL algorithms as Systems of Recurrence Equations (SREs). TempoRL is then able to holistically analyse and optimise this graph, applying both classic and novel transformations like automatic vectorisation (when memory allows) or incrementalisation (when memory is scarce).  Because SREs impose no control-flow, TempoRL is free to choose any execution schedule that respects the data dependencies. Luckily, by designing around SREs, we are able to leverage the powerful polyhedral analysis framework to find efficient and parallel execution schedules, as well as, compute a memory management plan through dataflow analysis. The remainder of the talk discusses the surprising advantages that this novel computational model brings, and the applications it may have outside of RL.
</p>
<p><b>[About the speaker]</b> Pedro Silvestre is a PhD student in the Large-Scale Data &amp; Systems Group at Imperial College London, under the supervision of Prof. Peter Pietzuch, working on Dataflow Systems for Deep Reinforcement Learning. Before Imperial, Pedro was a Research Engineer at the TU Delft’s Web Information Systems Group working on Consistent Fault-tolerance for Distributed Stream Processing. Pedro completed both his MSc and BSc from the NOVA School of Science and Technology. </p>
</div>
</div>
</div>
</div>
</div>
<!-- 
		<footer id="fh5co-footer">
			<div class="row">
				<div class="col-md-6 col-md-offset-3 text-center">
					<small>
						&copy; 2016 Personal Free HTML5 Template. All Rights Reserved. <span class="fh5co-author">
						Designed by <a href="http://freehtml5.co" target="_blank">FreeHTML5.co</a> Demo Images: <a href="http://unsplash.com/" target="_blank">Unsplash</a></span>
					</small>
				</div>
			</div>
		</footer>
        -->
</div>
<!-- jQuery -->
<script src="js/jquery.min.js"></script>
<!-- jQuery Easing -->
<script src="js/jquery.easing.1.3.js"></script>
<!-- Bootstrap -->
<script src="js/bootstrap.min.js"></script>
<!-- Waypoints -->
<script src="js/jquery.waypoints.min.js"></script>
<!-- Easy PieChart -->
<script src="js/jquery.easypiechart.min.js"></script>
<!-- MAIN JS -->
<script src="js/main.js"></script>
</body>
</html>
